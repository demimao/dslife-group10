---
title: "Clinical_feature_selection"
author: "Zhixin Mao"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(readxl)
library(reshape2)
library(dplyr)
library(ggplot2)
library(broom)
library(tidyverse)
library(ggpubr)
```

```{r}
df  <- data.frame(read_excel("./data/Supplementary_table.xlsx",sheet = 1))
names(df)
```

```{r}
# 161 of 168 cases had an RCB assessment
df <- df[which(df$RCB.category!="NA"),]
nrow(df) 
```

```{r}
y <- df
rownames(y) <- y$Donor.ID
# define variables to use
clinVariables <- c("Age", "T.stage", "LN.status.at.diagnosis", "Histology",
                   "ER.status", "HER2.status", "Grade.pre.NAT", 
                   "Chemo.cycles", "Number.of.LN.removed",
                   "RCB.category")

y <- y[, colnames(y) %in% clinVariables]

# Turn all RCB into 0, pCR into 1
y$RCB.category  <- factor(y$RCB.category,levels=c("RCB-III","RCB-II","RCB-I","pCR"),labels=c(0,0,0,1))

# Appropriately factor all variables
y$T.stage       <- as.numeric(substr(y$T.stage,2,2))
y$LN.status.at.diagnosis <- factor(y$LN.status.at.diagnosis, levels = c("POS", "NEG"))
y$Histology     <- factor(y$Histology=="IDC")
y$ER.status     <- factor(y$ER.status,levels=c("POS","NEG"))
y$HER2.status   <- factor(y$HER2.status,levels=c("NEG","POS"))
y$Grade.pre.NAT <- factor(y$Grade.pre.NAT,levels=c(2,3))
y$Chemo.cycles <- as.numeric(y$Chemo.cycles)
y$Number.of.LN.removed <- as.numeric(y$Number.of.LN.removed)

```

Before conducting feature selection and logistic regression, we examined the distribution of key clinical features across RCB outcome classes. This step reveals potential class imbalances and helps interpret model coefficients later.

```{r}
categorical_vars <- c("T.stage", "LN.status.at.diagnosis", "Histology", 
                      "ER.status", "HER2.status", "Grade.pre.NAT")

bar_plots <- lapply(categorical_vars, function(var) {
  ggplot(y, aes_string(x = var, fill = "RCB.category")) +
    geom_bar(position = "fill") +
    scale_y_continuous(labels = scales::percent_format()) +
    coord_flip() +
    labs(y = "Proportion", x = var, title = paste("Distribution of", var)) +
    theme_minimal(base_size = 12) +
    scale_fill_manual(values = c("#1f77b4", "#ff7f0e"))
})

ggarrange(plotlist = bar_plots, ncol = 2, nrow = 3, common.legend = TRUE, legend = "bottom")

```

```{r}
continuous_vars <- c("Age","Chemo.cycles", "Number.of.LN.removed")

box_plots <- lapply(continuous_vars, function(var) {
  ggplot(y, aes_string(x = "RCB.category", y = var, fill = "RCB.category")) +
    geom_boxplot(outlier.size = 1.5) +
    labs(y = var, x = NULL, title = paste(var, "across RCB categories")) +
    theme_minimal(base_size = 12) +
    scale_fill_manual(values = c("#1f77b4", "#ff7f0e")) +
    theme(legend.position = "none")
})

ggarrange(plotlist = box_plots, ncol = 2, nrow = 2)

```

```{r}
vars <- setdiff(colnames(y), "RCB.category")

# simple logistic regression
simpleLogisticRegression <- lapply(vars, function(var) {
  fml <- as.formula(paste("RCB.category ~", var))
  model <- glm(fml, data = y, family = "binomial")
  lrm <- summary(model)
  if (nrow(lrm$coefficients) < 2) return(NULL)
  pval <- lrm$coefficients[2, "Pr(>|z|)"]
  odds.ratio <- exp(lrm$coefficients[2, "Estimate"])
  conf <- suppressMessages(confint(model))
  ci.low <- exp(conf[2, 1])
  ci.hi <- exp(conf[2, 2])
  data.frame(variable = var, pval, odds.ratio, ci.low, ci.hi)
})

# combine results
regression.univariable <- do.call(rbind, simpleLogisticRegression)
regression.univariable$class <- "pCR"
regression.univariable$type <- "Simple logist."

# check results
print(regression.univariable)
```

## Interpretation

From the table, we observe that 

1. Older patients have lower odds of achieving pCR (−4.8% per year) — significant.
2. Larger tumor stage → significantly lower pCR odds. This is expected clinically.
3. In Ln status, there's significantly higher pCR rate in LN-negative tumors.
4. IDC histology has higher pCR odds than others. But confidence interval is large, we need to be careful.
5. ER-negative tumors are much more likely to respond (consistent with biology).
6. Better response in HER2+, but not statistically significant.
7. High-grade tumors (grade 3 vs 2) → significantly better response.
8. Slight increase in pCR odds per extra chemo cycle, but not significant.
9. For number of LN removed, slight negative association (likely a surrogate for worse disease burden).

```{r}
# Plot forest plot for simple logistic regression result

# Prepare plot data
plot_data <- regression.univariable %>%
  mutate(
    variable = factor(variable, levels = rev(variable)),  # reverse for top-down
    log_odds = log(odds.ratio),                           # log(OR) for symmetry
    sig = ifelse(pval < 0.05, "Significant", "Not significant")
  )

# Create forest plot
ggplot(plot_data, aes(x = variable, y = log_odds, ymin = log(ci.low), ymax = log(ci.hi))) +
  geom_pointrange(aes(color = sig), size = 0.6) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  coord_flip() +
  labs(
    title = "Univariable Logistic Regression - Forest Plot",
    x = NULL,
    y = "log(Odds Ratio)"
  ) +
  scale_color_manual(values = c("Significant" = "firebrick", "Not significant" = "grey40")) +
  theme_minimal(base_size = 14)
```

```{r}

# Multiple logistic regression
model <- glm(RCB.category ~ Age + T.stage + LN.status.at.diagnosis + Histology + ER.status + 
             HER2.status + Grade.pre.NAT + Chemo.cycles + Number.of.LN.removed, 
             family = "binomial", data = y)

# extract regression coefficients
summary_model <- summary(model)
conf <- suppressMessages(confint(model))[-1, , drop = FALSE]  # 去除 Intercept

# variables in summary
regression_multi <- data.frame(
  variable = rownames(summary_model$coefficients)[-1],
  estimate = summary_model$coefficients[-1, "Estimate"],
  pval = summary_model$coefficients[-1, "Pr(>|z|)"],
  odds.ratio = exp(summary_model$coefficients[-1, "Estimate"]),
  ci.low = exp(conf[, 1]),
  ci.high = exp(conf[, 2])
)

# adjust p-value（Benjamini-Hochberg）
regression_multi$padj <- p.adjust(regression_multi$pval, method = "BH")

# mark significance
regression_multi$sig <- ifelse(regression_multi$padj < 0.05, "Significant", "Not significant")

# set graph order
regression_multi$variable <- factor(regression_multi$variable, levels = rev(regression_multi$variable))

summary_model
print(regression_multi)
```

## Interpretation

The top is the summary table of multivariate logistic regression before adjusting p-value, and bottom is after adjusting p-value.

The number of statistically significant features have decreased after adjusting p value:

1. Age: Older age → less likely to achieve pCR 
2. ER.statusNEG: ER-negative → much more likely to achieve pCR


```

```{r}
ggplot(regression_multi, aes(x = variable, y = log(odds.ratio), 
                             ymin = log(ci.low), ymax = log(ci.high))) +
  geom_pointrange(aes(color = sig), size = 0.6) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  coord_flip() +
  labs(
    title = "Multiple Logistic Regression - Forest Plot",
    x = NULL,
    y = "log(Odds Ratio)",
    color = "Adjusted p-value"
  ) +
  scale_color_manual(values = c("Significant" = "firebrick", "Not significant" = "grey40")) +
  theme_minimal(base_size = 14)

```


